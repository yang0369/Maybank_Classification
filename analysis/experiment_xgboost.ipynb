{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import featuretools as ft\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import phik\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import (KFold, RandomizedSearchCV,\n",
    "                                     StratifiedKFold, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "from src.config import config\n",
    "from src.E2EPipeline import E2EPipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "task = pd.read_excel(\"/Users/kewenyang/Documents/GitHub/Maybank_Classification/data/Assessment.xlsx\",\n",
    "                       engine='openpyxl',\n",
    "                       sheet_name=0)\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "meta = pd.read_excel(\"/Users/kewenyang/Documents/GitHub/Maybank_Classification/data/Assessment.xlsx\",\n",
    "                       engine='openpyxl',\n",
    "                       sheet_name=2)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(\"/Users/kewenyang/Documents/GitHub/Maybank_Classification/data/Assessment.xlsx\",\n",
    "                       engine='openpyxl',\n",
    "                       sheet_name=1)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check target var distribution --> imbalance\n",
    "df_raw.C_seg.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_ID is not unique\n",
    "df_raw.loc[df_raw.C_ID == 59688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original C_ID and replace it by row index\n",
    "df_raw.drop(\"C_ID\", axis=1, inplace=True)\n",
    "df_raw.reset_index(drop=True, inplace=True)\n",
    "df_raw = df_raw.reset_index()\n",
    "df_raw.rename(columns={\"index\": \"C_ID\"}, inplace=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check col with more missing values\n",
    "missing = df_raw.isnull().any(axis=0)\n",
    "missing = missing.loc[missing == True].index\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in missing:\n",
    "    print(f\"for col - {col}:\")\n",
    "    print(df_raw[col].value_counts())\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing value with 0\n",
    "df_raw[\"HL_tag\"].fillna(value=0, inplace=True)\n",
    "df_raw[\"AL_tag\"].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this col as it's a dummy\n",
    "df_raw[\"PC\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop(\"PC\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.HL_tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns' categories\n",
    "nominal = [\"C_EDU\", \"C_HSE\", \"gn_occ\", \"HL_tag\", \"AL_tag\", \"C_seg\"]\n",
    "ordinal = [\"INCM_TYP\"]\n",
    "target_name = \"C_seg\"\n",
    "index_col = \"C_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_cols = [col for col in df_raw.columns if col not in (nominal + ordinal)]\n",
    "interval_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # explore overall correlations\n",
    "# df_corr = df_raw.loc[:, [c for c in df_raw.columns if c not in [\"AL_tag\", \"pur_price_avg\", \"UT_AVE\", \"MAXUT\", \"N_FUNDS\"]]]\n",
    "# phik_overview = df_corr.phik_matrix(interval_cols=interval_cols)\n",
    "# f = plt.figure(figsize=(15, 15))\n",
    "# plt.matshow(phik_overview, fignum=f.number, cmap=\"Reds\")\n",
    "# plt.xticks(range(df_corr.shape[1]), df_corr.columns, fontsize=8, rotation=90)\n",
    "# plt.yticks(range(df_corr.shape[1]), df_corr.columns, fontsize=8)\n",
    "# cb = plt.colorbar()\n",
    "# cb.ax.tick_params(labelsize=8)\n",
    "# plt.title('Correlation matrix', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_seg is relatively more correlated with C_AGE, gn_occ, NUM_PRD, CASATD_CNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical to string\n",
    "for col in (nominal + ordinal):\n",
    "    df_raw[col] = df_raw[col].astype(str)\n",
    "\n",
    "df_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After converting, np.nan has been converted to string as well\n",
    "df_raw.loc[(df_raw.isin([\"nan\", \"NaN\", \"NA\", \"Nan\", \"Nill\", \"NAN\"])).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map string back to np.nan\n",
    "df_raw.replace({\"nan\": np.nan, \"NaN\": np.nan, \"NAN\": np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare list of features for feature engineering\n",
    "counts = [\n",
    "    \"NUM_PRD\",\n",
    "    \"CASATD_CNT\",\n",
    "    \"N_FUNDS\",\n",
    "    \"ANN_N_TRX\",\n",
    "    ]\n",
    "\n",
    "values = [\n",
    "    \"MTHCASA\",\n",
    "    \"MAXCASA\",\n",
    "    \"MINCASA\",\n",
    "    \"pur_price_avg\",\n",
    "    \"UT_AVE\",\n",
    "    \"MAXUT\",\n",
    "    \"CC_AVE\",\n",
    "    \"MAX_MTH_TRN_AMT\",\n",
    "    \"MIN_MTH_TRN_AMT\",\n",
    "    \"MTHTD\",\n",
    "    \"MAXTD\",\n",
    "    \"Asset value\",\n",
    "    \"AVG_TRN_AMT\",\n",
    "    \"ANN_TRN_AMT\",\n",
    "    \"CC_LMT\",\n",
    "    ]\n",
    "\n",
    "# show the numeric columns not included in feature engineering list\n",
    "[col for col in df_raw.columns if ((df_raw[col].dtype != \"O\") and (col not in counts + values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare df for standardization\n",
    "stand_cols = counts + values + ['C_AGE', 'DRvCR']\n",
    "df_stand = df_raw.loc[:, stand_cols]\n",
    "df_raw.drop(stand_cols, axis=1, inplace=True)\n",
    "df_stand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "scaler = StandardScaler()\n",
    "feature_arr = scaler.fit_transform(df_stand.values)\n",
    "df_stand = pd.DataFrame(feature_arr, index=df_stand.index, columns=df_stand.columns)\n",
    "\n",
    "df_raw = pd.concat([df_raw, df_stand], axis=1)\n",
    "display(\"after scaling\", df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "# # check avail transform\n",
    "# ft.list_primitives()[ft.list_primitives().type == \"transform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering 1\n",
    "es = ft.EntitySet(id='ft')\n",
    "es = es.add_dataframe(dataframe_name=\"ft\", dataframe=df_raw.loc[:, values + [index_col]], index=index_col)\n",
    "\n",
    "features_matrix,feature_names = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='ft',\n",
    "    trans_primitives=[\"add_numeric\", \"subtract_numeric\", \"divide_numeric\",'multiply_numeric'],\n",
    "    max_depth=2,\n",
    "    verbose=True)\n",
    "\n",
    "features_matrix.reset_index(inplace=True)\n",
    "features_matrix = features_matrix.drop(values, axis=1)\n",
    "\n",
    "df_raw = df_raw.merge(features_matrix, how='left', on=index_col)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering 2\n",
    "es = ft.EntitySet(id='ft')\n",
    "es = es.add_dataframe(dataframe_name=\"ft\", dataframe=df_raw.loc[:, counts + [index_col]], index=index_col)\n",
    "\n",
    "features_matrix,feature_names = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name='ft',\n",
    "    trans_primitives=[\"add_numeric\", \"subtract_numeric\", \"divide_numeric\",'multiply_numeric'],\n",
    "    max_depth=2,\n",
    "    verbose=True)\n",
    "\n",
    "features_matrix.reset_index(inplace=True)\n",
    "features_matrix = features_matrix.drop(counts, axis=1)\n",
    "\n",
    "df_raw = df_raw.merge(features_matrix, how='left', on=index_col)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the customer_id\n",
    "df_X = df_raw.drop([index_col, target_name], axis=1)\n",
    "df_y = df_raw.loc[:, [target_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "X, X_test, y, y_test = train_test_split(df_X, df_y, test_size=0.1, random_state=1, shuffle=True, stratify=df_y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "display(f\"train set size: {X_train.shape}, val set size: {X_val.shape}, test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cols requiring onehotencoding\n",
    "categorical = [col for col in (ordinal + nominal) if col != target_name]\n",
    "display(f\"the categorical variables that need one hot encoding are: {categorical}\")\n",
    "\n",
    "# apply onehotencoding for categorical variables\n",
    "enc = OneHotEncoder(handle_unknown='error', sparse_output=False, drop=None)\n",
    "enc.fit_transform(df_X.loc[:, categorical])\n",
    "feature_labels = enc.get_feature_names_out()\n",
    "\n",
    "\n",
    "feature_arr = enc.transform(X[categorical])\n",
    "cat_X = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X = pd.concat([X.drop(categorical, axis=1).reset_index(drop=True), cat_X], axis=1)\n",
    "\n",
    "# for training data\n",
    "feature_arr = enc.transform(X_train[categorical])\n",
    "cat_train = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_train = pd.concat([X_train.drop(categorical, axis=1).reset_index(drop=True), cat_train], axis=1)\n",
    "display(\"training data after onehot encoding:\", X_train.head())\n",
    "\n",
    "feature_arr = enc.transform(X_val[categorical])\n",
    "cat_val = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_val = pd.concat([X_val.drop(categorical, axis=1).reset_index(drop=True), cat_val], axis=1)\n",
    "display(\"val data after onehot encoding:\", X_val.head())\n",
    "\n",
    "feature_arr = enc.transform(X_test[categorical])\n",
    "cat_test = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_test = pd.concat([X_test.drop(categorical, axis=1).reset_index(drop=True), cat_test], axis=1)\n",
    "display(\"test data after onehot encoding:\", X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing predictor values with np.nan, so that XGBoost will handle them\n",
    "X = X.replace(np.nan)\n",
    "X_train = X_train.replace(np.nan)\n",
    "X_val = X_val.replace(np.nan)\n",
    "X_test = X_test.replace(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencoder will encode the np.nan into a new column\n",
    "nan_cols = [col for col in X.columns if \"_nan\" in col]\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as onehot add extra nan column, so we need to remove it\n",
    "def impute_encoded_col(df: pd.DataFrame, col_lst: list) -> pd.DataFrame:\n",
    "    for col_n in col_lst:\n",
    "        key = col_n[:-4]\n",
    "        index =(df.loc[df[col_n] == 1]).index\n",
    "\n",
    "        # drop column\n",
    "        df.drop(col_n, axis=1, inplace=True)\n",
    "\n",
    "        # impute with np.nan\n",
    "        df.loc[index, [col for col in df.columns if key in col]] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "X = impute_encoded_col(X, nan_cols)\n",
    "\n",
    "X_train = impute_encoded_col(X_train, nan_cols)\n",
    "display(\"train set after imputing:\", X_train.sample(1))\n",
    "\n",
    "X_val = impute_encoded_col(X_val, nan_cols)\n",
    "display(\"val set after imputing:\", X_val.sample(1))\n",
    "\n",
    "X_test = impute_encoded_col(X_test, nan_cols)\n",
    "display(\"test set after imputing:\", X_test.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to drop useless columns based on feature selection\n",
    "useless = ['C_HSE_OFFICE',\n",
    " 'ANN_TRN_AMT / AVG_TRN_AMT',\n",
    " 'C_HSE_COMMERICAL BUILDING',\n",
    " 'AVG_TRN_AMT / ANN_TRN_AMT',\n",
    " 'C_HSE_INDUSTRIAL BUILDING',\n",
    " 'C_HSE_HOTEL/ SERVICE APARTMENT']\n",
    "\n",
    "X.drop(useless, axis = 1, inplace=True)\n",
    "X_train.drop(useless, axis = 1, inplace=True)\n",
    "X_val.drop(useless, axis = 1, inplace=True)\n",
    "X_test.drop(useless, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for target variable\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = pd.DataFrame(le.fit_transform(y[target_name]), columns=[\"Y\"])\n",
    "\n",
    "y_train = pd.DataFrame(le.transform(y_train[target_name]), columns=[\"Y\"])\n",
    "display(\"training after label encoding:\", y_train.head())\n",
    "\n",
    "y_val = pd.DataFrame(le.transform(y_val[target_name]), columns=[\"Y\"])\n",
    "display(\"y_val after label encoding:\", y_val.head())\n",
    "\n",
    "y_test = pd.DataFrame(le.transform(y_test[target_name]), columns=[\"Y\"])\n",
    "display(\"y_test after label encoding:\", y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.values == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sample weights\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# parameters\n",
    "objective='binary:logistic'\n",
    "booster = \"gbtree\"\n",
    "eval_metric=\"logloss\"\n",
    "early_stopping_rounds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Finetune Hyperparameters\n",
    "# params = {\n",
    "#     \"colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#     \"gamma\": uniform(0.3, 0.7),\n",
    "#     \"max_depth\": [8, 9, 10, 11, 12],\n",
    "#     \"n_estimators\": randint(30, 80),\n",
    "#     \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "#     \"min_child_weight\": [1, 1.5, 2, 2.5],\n",
    "#     \"eta\": [0.3, 0.1, 0.05],\n",
    "# }\n",
    "\n",
    "# k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "# scoring=\"f1\"\n",
    "\n",
    "# cv_model = xgb.XGBClassifier(\n",
    "#     objective=objective,\n",
    "#     tree_method= \"auto\",\n",
    "#     eval_metric=eval_metric,\n",
    "#     booster = booster)\n",
    "\n",
    "# search = RandomizedSearchCV(\n",
    "#     cv_model,\n",
    "#     param_distributions=params,\n",
    "#     scoring=scoring,\n",
    "#     random_state=1,\n",
    "#     n_iter=100,  # No. of combinations / fold\n",
    "#     cv=k,\n",
    "#     verbose=1,\n",
    "#     n_jobs=1,\n",
    "#     return_train_score=True,\n",
    "#     refit=False,  # refit by manual as we need to plot the train-val curve to see overfitting problem\n",
    "#     )\n",
    "\n",
    "# search.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "# cv_results =  pd.DataFrame(search.cv_results_).loc[:, [\"rank_test_score\", \"mean_test_score\", \"params\"]].sort_values(by=[\"rank_test_score\"])\n",
    "# cv_results.head(5)\n",
    "\n",
    "# # show the best set of hyperparams\n",
    "# search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train-val curve to ensure no overfitting\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "colsample_bytree = 0.6\n",
    "n_estimators = 69\n",
    "tree_method= \"auto\"\n",
    "\n",
    "# tuning parameters\n",
    "eta = 0.3\n",
    "max_depth = 10\n",
    "max_leaves = 2 ** max_depth\n",
    "\n",
    "# prevent overfitting\n",
    "min_child_weight = 1.5\n",
    "gamma = 0.45095519663195377\n",
    "subsample = 0.9\n",
    "\n",
    "\n",
    "# Use \"hist\" for constructing the trees, with early stopping enabled.\n",
    "model = xgb.XGBClassifier(\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    tree_method=tree_method,\n",
    "    objective=objective,\n",
    "    n_estimators=n_estimators,\n",
    "    missing=np.nan,\n",
    "    eval_metric=eval_metric,\n",
    "    booster=booster,\n",
    "    eta=eta,\n",
    "    max_depth=max_depth,\n",
    "    max_leaves=max_leaves,\n",
    "    min_child_weight=min_child_weight,\n",
    "    gamma=gamma,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree)\n",
    "\n",
    "# Fit the model, val sets are used for early stopping.\n",
    "result = model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], sample_weight=sample_weights, verbose=True)\n",
    "\n",
    "# check overfitting\n",
    "results = result.evals_result()\n",
    "epochs = len(results['validation_0']['logloss'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['logloss'], label='Validation')\n",
    "ax.legend()\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('XGBoost Log Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally train with all traing + val, and change to dart booster\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y\n",
    ")\n",
    "\n",
    "colsample_bytree = 0.6\n",
    "n_estimators = 69\n",
    "tree_method= \"auto\"\n",
    "# booster = \"dart\"  # update booster to dart\n",
    "booster = \"gbtree\"\n",
    "\n",
    "# tuning parameters\n",
    "eta = 0.3\n",
    "max_depth = 10\n",
    "max_leaves = 2**max_depth\n",
    "\n",
    "# prevent overfitting\n",
    "min_child_weight = 1.5\n",
    "gamma = 0.45095519663195377\n",
    "subsample = 0.9\n",
    "\n",
    "\n",
    "# Use \"hist\" for constructing the trees, with early stopping enabled.\n",
    "model = xgb.XGBClassifier(\n",
    "    tree_method=tree_method,\n",
    "    objective=objective,\n",
    "    n_estimators=n_estimators,\n",
    "    missing=np.nan,\n",
    "    eval_metric=eval_metric,\n",
    "    booster=booster,\n",
    "    eta=eta,\n",
    "    max_depth=max_depth,\n",
    "    max_leaves=max_leaves,\n",
    "    min_child_weight=min_child_weight,\n",
    "    gamma=gamma,\n",
    "    subsample=subsample,\n",
    "    colsample_bytree=colsample_bytree)\n",
    "\n",
    "model.fit(X, y, verbose=True, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "preds = model.predict(X_train)\n",
    "\n",
    "# 0.9130316495873766\n",
    "f1_score(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# 0.9130316495873766\n",
    "f1_score(y_val, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# 0.9196223751544026\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold Moving/Tuning\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "\n",
    "yhat = model.predict_proba(X_val)\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = yhat[:, 1]\n",
    "\n",
    "# define thresholds\n",
    "thresholds = arange(0, 1, 0.001)\n",
    "\n",
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "\n",
    "# evaluate each threshold\n",
    "scores = [f1_score(y_val, to_labels(probs, t)) for t in thresholds]\n",
    "# get best threshold\n",
    "ix = argmax(scores)\n",
    "\n",
    "best_thresh = thresholds[ix]\n",
    "\n",
    "print('Best performing threshold=%.3f with best F-Score=%.5f' % (best_thresh, scores[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "preds = (prob > best_thresh).astype(\"int\")\n",
    "\n",
    "# 0.9228875406664908\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the feature importance\n",
    "feature_imp = pd.DataFrame(sorted(zip(model.feature_names_in_, model.feature_importances_), key=lambda x: x[0], reverse=True), columns=['Feature', 'Value'])\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "data = feature_imp.sort_values(by=\"Value\", ascending=False).head(50)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=data)\n",
    "ax.set_title('Feature Importance By Weight')\n",
    "ax.set_xlabel('importance score')\n",
    "ax.set_ylabel('features')\n",
    "ax.yaxis.set_visible(True)\n",
    "ax.xaxis.set_visible(True)\n",
    "fig.patch.set_facecolor('white')\n",
    "# plt.savefig(f'../data/feature_importance_by_weight.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the useless col in prediction\n",
    "useless_cols = feature_imp.sort_values(by=\"Value\", ascending=False).loc[feature_imp.sort_values(by=\"Value\", ascending=False).Value == 0, \"Feature\"].tolist()\n",
    "useless_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values.values, X_test, max_display=10, show=False, plot_type=\"dot\", plot_size=[10,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After all the analysis, we have built the end to end pipeline for production\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline\n",
    "df_raw = pd.read_excel(\"/Users/kewenyang/Documents/GitHub/Maybank_Classification/data/Assessment.xlsx\",\n",
    "                       engine='openpyxl',\n",
    "                       sheet_name=1)\n",
    "\n",
    "pipe = E2EPipeline()\n",
    "data = pipe.preprocess(df_raw)\n",
    "f1 = pipe.train(data)\n",
    "print(f\"the f1 score is: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
