{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "if ROOT not in sys.path:\n",
    "    sys.path.append(ROOT)\n",
    "\n",
    "from src.config import config\n",
    "from src.E2EPipeline import E2EPipeline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# update jupyter kernel automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(\"/Users/kewenyang/Documents/GitHub/Maybank_Classification/data/Assessment.xlsx\",\n",
    "                       engine='openpyxl',\n",
    "                       sheet_name=1)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = E2EPipeline()\n",
    "df_raw = pipe.preprocess(df_raw, True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df_raw.isnull().sum(axis=0) / df_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the customer_id\n",
    "df_X = df_raw.drop([config.index_col, config.target_name], axis=1)\n",
    "df_y = df_raw.loc[:, [config.target_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "X, X_test, y, y_test = train_test_split(df_X, df_y, test_size=0.1, random_state=1, shuffle=True, stratify=df_y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "display(f\"train set size: {X_train.shape}, val set size: {X_val.shape}, test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cols requiring onehotencoding\n",
    "categorical = [col for col in (config.ordinal + config.nominal) if col != config.target_name]\n",
    "categorical.remove('HL_tag')\n",
    "categorical.remove('AL_tag')\n",
    "\n",
    "display(f\"the categorical variables that need one hot encoding are: {categorical}\")\n",
    "\n",
    "# apply onehotencoding for categorical variables\n",
    "enc = OneHotEncoder(handle_unknown='error', sparse_output=False, drop=None)\n",
    "enc.fit_transform(df_X.loc[:, categorical])\n",
    "feature_labels = enc.get_feature_names_out()\n",
    "\n",
    "\n",
    "feature_arr = enc.transform(X[categorical])\n",
    "cat_X = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X = pd.concat([X.drop(categorical, axis=1).reset_index(drop=True), cat_X], axis=1)\n",
    "\n",
    "# for training data\n",
    "feature_arr = enc.transform(X_train[categorical])\n",
    "cat_train = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_train = pd.concat([X_train.drop(categorical, axis=1).reset_index(drop=True), cat_train], axis=1)\n",
    "display(\"training data after onehot encoding:\", X_train.head())\n",
    "\n",
    "feature_arr = enc.transform(X_val[categorical])\n",
    "cat_val = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_val = pd.concat([X_val.drop(categorical, axis=1).reset_index(drop=True), cat_val], axis=1)\n",
    "display(\"val data after onehot encoding:\", X_val.head())\n",
    "\n",
    "feature_arr = enc.transform(X_test[categorical])\n",
    "cat_test = pd.DataFrame(feature_arr, columns=feature_labels).reset_index(drop=True)\n",
    "X_test = pd.concat([X_test.drop(categorical, axis=1).reset_index(drop=True), cat_test], axis=1)\n",
    "display(\"test data after onehot encoding:\", X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try to drop useless columns based on feature selection\n",
    "useless = ['C_HSE_OFFICE',\n",
    " 'ANN_TRN_AMT / AVG_TRN_AMT',\n",
    " 'C_HSE_COMMERICAL BUILDING',\n",
    " 'AVG_TRN_AMT / ANN_TRN_AMT',\n",
    " 'C_HSE_INDUSTRIAL BUILDING',\n",
    " 'C_HSE_HOTEL/ SERVICE APARTMENT']\n",
    "\n",
    "X.drop(useless, axis = 1, inplace=True)\n",
    "X_train.drop(useless, axis = 1, inplace=True)\n",
    "X_val.drop(useless, axis = 1, inplace=True)\n",
    "X_test.drop(useless, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for target variable\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y = pd.DataFrame(le.fit_transform(y[config.target_name]), columns=[\"Y\"])\n",
    "\n",
    "y_train = pd.DataFrame(le.transform(y_train[config.target_name]), columns=[\"Y\"])\n",
    "display(\"training after label encoding:\", y_train.head())\n",
    "\n",
    "y_val = pd.DataFrame(le.transform(y_val[config.target_name]), columns=[\"Y\"])\n",
    "display(\"y_val after label encoding:\", y_val.head())\n",
    "\n",
    "y_test = pd.DataFrame(le.transform(y_test[config.target_name]), columns=[\"Y\"])\n",
    "display(\"y_test after label encoding:\", y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsamping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=1, k_neighbors=5)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = MLPClassifier(random_state=1, max_iter=100).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict on test set\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# 0.9228875406664908\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
